Here you can find a more detailed explanation of the model and its implementation.


First a description of the main parameters of the model and its notation:

- num_dimen == number of possibly dependent dimensions. In our frame can be only 1 if you want to have a time-dependent predictor and use input_driven observation.
- num_categorical_obs == when you are using input_driven observation you have to specify the finite possible outcome of your neural response time series. In this frame is equal to 2 (binary, Bernoulli)
- N_iters == maximum number of iterations before interrupting the procedure, regardless of the optimization function value (log-likelihood)
- tolerance == threshold on the optimization function value. Once is reached, the optimization is stopped
- num_indep_neurons == if you want to consider neurons as independent, this is the number of cells you are including (the final likelihood is the product of the probability of each neuron)
- num_predicotrs == number of predictors you want to include in the inference 
- max_num_states == if you want to test the model for a different number of states, you can declare here the maximum number of states you want and the code will test models including 2 states up to "max_num_states" (this is done by "list_states")
- observation_type == type of distribution you want to study. In our frame, the simplest approach would be Bernoulli. Nonetheless, the ssm package allows the use of an input_driven observation to allow any distribution given the constraint on the categorical variable 
- transistion_type == it select the type of transition. In practice, it selects the method and the constraint on the transition probabilities
- optim_method == optimization method to fit the log-likelihood and transition probability (in addition to the initial probabilities on the states)

Below a general overview of the theory.

...
...


References for theory:
L. Paniski; Statistical analysis of neural data: Discrete-space hidden Markov models; http://www.stat.columbia.edu/âˆ¼liam
